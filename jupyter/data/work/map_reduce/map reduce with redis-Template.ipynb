{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# MapReduce Implementation with Redis Backend\n",
    "\n",
    "This notebook demonstrates a **distributed MapReduce implementation** using Redis as the backend for job coordination and data storage.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand MapReduce paradigm fundamentals\n",
    "- Implement distributed processing with Redis\n",
    "- Compare sequential vs parallel execution\n",
    "- Analyze performance improvements\n",
    "\n",
    "## Use Case: Word Frequency Analysis\n",
    "We'll analyze Dante's Divine Comedy to count word frequencies across the three canticles (Inferno, Purgatorio, Paradiso).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-section",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "First, let's install required dependencies and establish our Redis connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-deps",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install required packages\n",
    "%pip install redis rich tqdm beautifulsoup4 requests rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports for our MapReduce implementation\n",
    "import redis\n",
    "import json\n",
    "import time\n",
    "from multiprocessing import Process\n",
    "\n",
    "# Data fetching and processing\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Utilities for better output\n",
    "from rich.pretty import pprint\n",
    "from rich.console import Console\n",
    "from tqdm import tqdm\n",
    "\n",
    "console = Console()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "redis-connection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redis Cluster Connection\n",
    "# Note: Make sure your Jupyter server is connected to the Redis network\n",
    "# Command: docker network connect redis_default jupyter-jupyter-1\n",
    "\n",
    "try:\n",
    "    r = redis.RedisCluster(host='master', port=6379)\n",
    "    console.print(\"✅ Redis cluster connection established\", style=\"green\")\n",
    "except Exception as e:\n",
    "    console.print(f\"❌ Redis connection failed: {e}\", style=\"red\")\n",
    "    # Fallback to local Redis if cluster is not available\n",
    "    r = redis.Redis(host='localhost', port=6379, decode_responses=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-section",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preparation\n",
    "\n",
    "Let's fetch Dante's Divine Comedy from the web and prepare it for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helper-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for Redis operations\n",
    "def store(key, record):\n",
    "    \"\"\"Store a record in Redis as JSON\"\"\"\n",
    "    r.sadd(key, json.dumps(record))\n",
    "\n",
    "def fetch(key):\n",
    "    \"\"\"Fetch and remove a record from Redis\"\"\"\n",
    "    raw = r.spop(key)\n",
    "    return json.loads(raw) if raw is not None else None\n",
    "\n",
    "def cleanup_keys(pattern):\n",
    "    \"\"\"Clean up Redis keys matching a pattern\"\"\"\n",
    "    keys_to_delete = [key for key in r.scan_iter(pattern)]\n",
    "    if keys_to_delete:\n",
    "        for key in keys_to_delete:\n",
    "            r.delete(key)\n",
    "    return len(keys_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_divine_comedy():\n",
    "    \"\"\"\n",
    "    Load Dante's Divine Comedy from online source\n",
    "    Splits text into individual cantos for processing\n",
    "    \"\"\"\n",
    "    console.print(\"🧹 Cleaning up previous data...\")\n",
    "    \n",
    "    # Clean up any existing data\n",
    "    r.delete(\"dante_comedy:cantos\")\n",
    "    cleanup_keys(\"dante_comedy:max_count:step_*\")\n",
    "    \n",
    "    console.print(\"📚 Loading Dante's Divine Comedy...\")\n",
    "    \n",
    "    # URLs for the three canticles\n",
    "    urls = {\n",
    "        \"inferno\": \"https://www.liberliber.eu/mediateca/libri/a/alighieri/la_divina_commedia/html/testo_01.htm\",\n",
    "        \"purgatorio\": \"https://www.liberliber.eu/mediateca/libri/a/alighieri/la_divina_commedia/html/testo_02.htm\",\n",
    "        \"paradiso\": \"https://www.liberliber.eu/mediateca/libri/a/alighieri/la_divina_commedia/html/testo_03.htm\"\n",
    "    }\n",
    "    \n",
    "    total_cantos = 0\n",
    "    \n",
    "    for cantica_name, url in urls.items():\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # Extract text from paragraphs with class 'rientrato'\n",
    "            cantos = soup.select(\"p.rientrato\")\n",
    "            \n",
    "            for canto in cantos:\n",
    "                if canto.text.strip():  # Only store non-empty cantos\n",
    "                    store(\"dante_comedy:cantos\", {\n",
    "                        \"cantica\": cantica_name,\n",
    "                        \"text\": canto.text.strip()\n",
    "                    })\n",
    "                    total_cantos += 1\n",
    "                    \n",
    "        except Exception as e:\n",
    "            console.print(f\"❌ Error loading {cantica_name}: {e}\", style=\"red\")\n",
    "    \n",
    "    console.print(f\"✅ Data loaded successfully! Total cantos: {total_cantos}\")\n",
    "    return total_cantos\n",
    "\n",
    "# Load the data\n",
    "canto_count = load_divine_comedy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mapreduce-section",
   "metadata": {},
   "source": [
    "## 3. MapReduce Functions\n",
    "\n",
    "Now let's define our **Map** and **Reduce** functions for word frequency analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "map-reduce-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_words(record):\n",
    "    \"\"\"\n",
    "    MAP FUNCTION: Extract words from text and emit (word-cantica, 1) pairs\n",
    "    \n",
    "    Input: {'cantica': 'inferno', 'text': 'Nel mezzo del cammin...'}\n",
    "    Output: Generator of (key, value) pairs\n",
    "    \"\"\"\n",
    "    text = record[\"text\"]\n",
    "    cantica = record[\"cantica\"]\n",
    "    \n",
    "    # Clean text: remove punctuation\n",
    "    punctuation = \",.«»!?:;\\\"'()\"\n",
    "    clean_text = \"\".join(c for c in text if c not in punctuation)\n",
    "    \n",
    "    # Emit (word-cantica, 1) for each word\n",
    "    for word in clean_text.split():\n",
    "        if word.strip():  # Skip empty strings\n",
    "            yield f\"{word.lower()}-{cantica}\", 1\n",
    "\n",
    "def count_word(key, records):\n",
    "    \"\"\"\n",
    "    REDUCE FUNCTION: Sum up counts for each word\n",
    "    \n",
    "    Input: key='nel-inferno', records=[1, 1, 1, ...]\n",
    "    Output: Generator of (word, total_count) pairs\n",
    "    \"\"\"\n",
    "    word, cantica = key.split(\"-\", 1)\n",
    "    total_count = sum(records)\n",
    "    yield word, total_count\n",
    "\n",
    "def max_count(key, records):\n",
    "    \"\"\"\n",
    "    REDUCE FUNCTION: Find max and total counts across canticles\n",
    "    \n",
    "    Input: key='nel', records=[45, 32, 28]\n",
    "    Output: Generator of (word, {max, total}) pairs\n",
    "    \"\"\"\n",
    "    yield key, {\n",
    "        \"max\": max(records),\n",
    "        \"total\": sum(records)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a113e8a2-5ebe-459a-a3fb-c9c801f2b3ac",
   "metadata": {},
   "source": [
    "### 3.1. Simple Word Counting in Python\n",
    "\n",
    "Before implementing the distributed version, let's create a simple Python-only word count to understand the data flow. This will help you appreciate the benefits of the distributed approach we'll build later.\n",
    "\n",
    "**Exercise**: Use the provided map_words() function to implement a basic word count algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d38413c-be31-4183-97b8-e526929d35c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all cantos from Redis into memory for sequential processing\n",
    "# This simulates having all data available locally (non-distributed approach)\n",
    "cantos = [json.loads(canto) for canto in r.smembers(\"dante_comedy:cantos\")]\n",
    "\n",
    "print(f\"📚 Loaded {len(cantos)} cantos for sequential processing\")\n",
    "print(f\"📄 Sample canto: {cantos[0]['cantica']} - {cantos[0]['text'][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cd06b5-5e22-4f99-950c-588f081e0f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Apply map function to collect (word-cantica, count) pairs\n",
    "step1 = {}\n",
    "for canto in cantos:\n",
    "    for key, value in map_words(canto):\n",
    "        step1.setdefault(key, []).append(value)\n",
    "\n",
    "print(f\"🔍 Step 1 complete: {len(step1)} unique word-cantica pairs\")\n",
    "print(\"📊 Sample mappings:\")\n",
    "# Show a few examples\n",
    "for i, (key, values) in enumerate(list(step1.items())[:3]):\n",
    "    print(f\"   {key}: {values[:5]}{'...' if len(values) > 5 else ''}\")\n",
    "\n",
    "# Step 2: Reduce to get word counts per cantica\n",
    "step2 = {}\n",
    "# Your code here: use count_word function to aggregate counts\n",
    "\n",
    "# Step 3: Reduce to get max/total counts per word  \n",
    "step3 = {}\n",
    "# Your code here: use max_count function to find max and total\n",
    "\n",
    "# Step 4: Display results\n",
    "# Your code here: show top 10 most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24151f54-a92c-414a-b29c-8ff386dc11c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
